{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Krylov Subspace\n",
    "\n",
    "The pure iteration has the form\n",
    "\n",
    "$$Px_{k+1} = (P-A)x_k+b$$\n",
    "\n",
    "For simplicity, we choose $P = I$ and $x_1 = b$, thus the whole iterations are only to do with $A$ and $b$\n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "x_1 = b\\\\\n",
    "x_2 = (I-A)b+b = 2b-Ab\\\\\n",
    "x_3 = (I-A)x_1 + b = 3b-3Ab + A^2b\n",
    "\\end{array}$$\n",
    "\n",
    "The point is simple but important: $x_j$ is a combination of $b, Ab, \\cdots, A^{j-1}b$. And the linear combinations of these vectors form the $j^{th}$ Krylov subspace.\n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "\\text{Krylov matrix} &K_j = [b\\ Ab\\ A^2b\\ \\cdots\\ A^{j-1}b]\\\\\n",
    "\\text{Krylov subspace} &\\mathcal{K}_j = \\text{all combinations of }b,Ab,\\cdots, A^{j-1}b\n",
    "\\end{array}$$\n",
    "\n",
    "The problem is what is the best choise of $x_j$ in the Krylov subspace. Here are four different approaches to choosing a good $x_j$ in $\\mathcal{K}_j$.\n",
    "\n",
    "1. The residual $r_j = b-Ax_j$ is orthogonal to $\\mathcal{K}_j$ (**Conjugate Gradients**).\n",
    "2. The residual $r_j$ has minimum norm for $x_j$ in $\\mathcal{K}_j$ (**GMRES and MINRES**).\n",
    "3. $r_j$ is orthogonal to a different space $\\mathcal{K}_j(A^T)$ (**BiConjugate Gradients**).\n",
    "4. The error $e_j$ has minimum norm (**SYMMLQ**).\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "# Arnoldi's Method\n",
    "\n",
    "\n",
    "Before discussing the Conjugate Gradient method, we should extract orthonormal basis from the Krylov matrix to represent the basis of the Krylov subspace for simplifying the upcoming calculation.\n",
    "\n",
    "$$\\text{Krylov subspace}\\quad \\mathcal{K}_j = \\text{all combinations of }q_1,q_2,\\cdots, q_{j-1}$$\n",
    "\n",
    "Each new $q_j$ comes from orthogonalizing $t=Aq_{j-1}$ (which has the same direction as $A^{j-1}b$) to the basis vectors $q_1,\\cdots, q_{j-1}$ that are already chosen. The iteration to compute these orthonormal $q$'s is **Arnoldi's method**. This method is essentially the Gram-Schmidt idea.\n",
    " \n",
    "\n",
    "| Step |  Pseudocode | Discription |\n",
    "| ---- | :---------- | :----------- |\n",
    "|<img width=30/>|<img width=200/>|<img width=200/>|\n",
    "| 0   | $q_1 = b/\\|b\\|$            | Normalize $b$ to $\\|q_1\\| = 1$ |\n",
    "|&nbsp;| for $j = 1,\\cdots,n-1$       | Start computation of $q_{j+1}$|\n",
    "| 1   | &emsp; $t = Aq_j\\qquad\\ $      | one matrix multiplication|\n",
    "|&nbsp;| &emsp; for $i = 1,\\cdots,j$     | $t$ is in the space $\\mathcal{K}_{j+1}$| \n",
    "| 2   | &emsp; &emsp; $h_{ij} = q_i^Tt$   | $h_{ij}q_i =$ projection of $t$ on $q_i$|\n",
    "| 3   | &emsp; &emsp; $t = t-h_{ij}q_i$   | Subtract that projection |\n",
    "|&nbsp;| &emsp; end                | $t$ is orthogonal to $q_1, \\cdots, q_j$ |\n",
    "| 4   | &emsp; $h_{j+1,j} = \\|t\\|$      | Compute the length of $t$ |\n",
    "| 5   | &emsp; $q_{j+1} = t/h_{j+1,j}$  | Normalize $t$ to $\\|q_{j+1}\\|=1$ |\n",
    "|&nbsp;| end                    | $q_1,\\cdots,q_n$ are orthonormal |\n",
    "\n",
    "<font color='#aaaaaa'>*Custom table alignment seems to be supported after version 5.8 in Jupyter notebook. <a href='https://github.com/jupyter/notebook/pull/4130'>#4130</a>*</font>\n",
    "\n",
    "where $Aq_j$ is in the $\\mathcal{K}_{j+1}$ subspace, that is to say, $Aq_j$ is the linear combination of $q_1, \\cdots, q_j, q_{j+1}$, and the weights of these orthonormal vectors are $h_{1j},\\cdots, h_{jj}, h_{j+1,j}$. The Arnoldi's method can therefore be denoted by\n",
    "\n",
    "$$AQ = \\begin{bmatrix}\n",
    "\\\\\n",
    "\\\\\n",
    "Aq_1 &Aq_2 &\\cdots &Aq_n\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\\\\n",
    "\\\\\n",
    "q_1 &q_2 &\\cdots &q_n\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "h_{1,1} &h_{1,2} &\\cdots &h_{1,n-1} &h_{1,n}\\\\\n",
    "h_{2,1} &h_{2,2} &\\cdots &h_{2,n-1} &h_{2,n}\\\\\n",
    "0    &h_{3,2} &\\cdots &h_{3,n-1} &h_{3,n}\\\\\n",
    "\\vdots &\\vdots &\\ddots &\\vdots &\\vdots\\\\\n",
    "0 &0 &\\cdots &h_{n, n-1} &h_{n,n}\n",
    "\\end{bmatrix}\n",
    "=QH$$\n",
    "\n",
    "This matrix $H$ is upper triangular plus one lower diagonal, which makes it \"upper Hessenberg\".\n",
    "\n",
    "\n",
    "# Lanczos method\n",
    "\n",
    "If $A$ is symmetric, then\n",
    "\n",
    "$$\\left.\\begin{array}{ll}\n",
    "AQ=QH\\Rightarrow A=QHQ^T\\\\\n",
    "A^T=A\n",
    "\\end{array}\\right\\}\\Rightarrow H=H^T \\Rightarrow H=\\begin{bmatrix}\n",
    "h_{1,1} &h_{1,2} &\\cdots &0 &0\\\\\n",
    "h_{2,1} &h_{2,2} &\\cdots &0 &0\\\\\n",
    "0    &h_{3,2} &\\cdots &0 &0\\\\\n",
    "\\vdots &\\vdots &\\ddots &\\vdots &\\vdots\\\\\n",
    "0 &0 &\\cdots &h_{n, n-1} &h_{n,n}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$H$ is tridiagonal. Since $H$ has three nonzeros in its rows and columns. So computing $q_{j+1}$ only involves $q_j$ and $q_{j-1}$:\n",
    "\n",
    "$$Aq_j = h_{j+1,j}q_{j+1} + h_{j,j}q_j + h_{j-1,j}q_{j-1}$$\n",
    "\n",
    "This is the **Lanczos iteration**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
